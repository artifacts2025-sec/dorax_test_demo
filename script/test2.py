import os
import cv2
import argparse
import tkinter as tk
from PIL import Image, ImageTk, ImageFilter
from typing import List, Optional
import numpy as np
from scipy.ndimage import gaussian_filter
import subprocess
from natsort import natsorted

# è§†é¢‘ç¼–ç å¸¸é‡
FPS = 30
FINAL_CODEC = "libx264"
BITRATE = "2M"

class TriggerInserter:
    def __init__(self, trigger_img_path: str, feather_radius: float = 0.0, brightness_factor: float = 1.0):
        self.trigger_img_path = trigger_img_path
        self.feather_radius = feather_radius
        self.brightness_factor = brightness_factor
        self.trigger_img_orig = None
        self.workspace_img = None
        self.root = None
        self.canvas = None
        self.trigger_scale = 1.0
        self.trigger_position = [100, 100]
        self.trigger_rotation = 0
        self.dragging = False
        self.trigger_img_scaled = None
        self.current_frame_path = None
        self.settings_saved = False
        
    def adjust_brightness(self, image: Image.Image) -> Image.Image:
        """è°ƒæ•´å›¾åƒäº®åº¦"""
        if self.brightness_factor == 1.0:
            return image
            
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        img_array = np.array(image)
        
        if len(img_array.shape) == 3 and img_array.shape[2] == 4:
            # æœ‰alphaé€šé“ï¼Œåªè°ƒæ•´RGBé€šé“
            rgb_channels = img_array[:, :, :3].astype(np.float32)
            alpha_channel = img_array[:, :, 3]
            
            # è°ƒæ•´äº®åº¦
            rgb_channels *= self.brightness_factor
            rgb_channels = np.clip(rgb_channels, 0, 255)
            
            # é‡æ–°ç»„åˆ
            img_array = np.dstack([rgb_channels.astype(np.uint8), alpha_channel])
        else:
            # æ²¡æœ‰alphaé€šé“ï¼Œè°ƒæ•´æ•´ä¸ªå›¾åƒ
            img_array = img_array.astype(np.float32)
            img_array *= self.brightness_factor
            img_array = np.clip(img_array, 0, 255).astype(np.uint8)
            
        return Image.fromarray(img_array, 'RGBA' if len(img_array.shape) == 3 and img_array.shape[2] == 4 else 'RGB')
    
    def apply_feather_effect(self, image: Image.Image) -> Image.Image:
        """å¯¹å›¾åƒè¾¹ç¼˜åº”ç”¨ç¾½åŒ–æ•ˆæœ"""
        if self.feather_radius <= 0:
            return image
            
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        img_array = np.array(image)
        
        if len(img_array.shape) != 3 or img_array.shape[2] != 4:
            # å¦‚æœæ²¡æœ‰alphaé€šé“ï¼Œç›´æ¥è¿”å›åŸå›¾
            return image
            
        # è·å–alphaé€šé“
        alpha = img_array[:, :, 3].astype(np.float32) / 255.0
        
        # åˆ›å»ºè·ç¦»å˜æ¢æ¥è®¡ç®—åˆ°è¾¹ç¼˜çš„è·ç¦»
        # å…ˆæ‰¾åˆ°è¾¹ç¼˜ï¼ˆalphaå€¼åœ¨0-1ä¹‹é—´çš„åƒç´ ï¼‰
        edge_mask = (alpha > 0) & (alpha < 1)
        
        # å¯¹äºå®Œå…¨é€æ˜çš„åŒºåŸŸï¼Œè®¡ç®—åˆ°éé€æ˜åŒºåŸŸçš„è·ç¦»
        binary_mask = (alpha > 0).astype(np.uint8)
        
        # ä½¿ç”¨è·ç¦»å˜æ¢
        from scipy.ndimage import distance_transform_edt
        distances = distance_transform_edt(binary_mask)
        
        # åº”ç”¨ç¾½åŒ–ï¼šåœ¨è¾¹ç¼˜é™„è¿‘åˆ›å»ºæ¸å˜
        feather_mask = np.ones_like(alpha)
        fade_region = distances <= self.feather_radius
        
        # åœ¨ç¾½åŒ–åŒºåŸŸå†…åˆ›å»ºæ¸å˜
        feather_mask[fade_region] = distances[fade_region] / self.feather_radius
        
        # åº”ç”¨ç¾½åŒ–æ•ˆæœåˆ°alphaé€šé“
        alpha_feathered = alpha * feather_mask
        
        # è¿˜å¯ä»¥å¯¹alphaé€šé“åº”ç”¨é«˜æ–¯æ¨¡ç³Šæ¥è¿›ä¸€æ­¥æŸ”åŒ–è¾¹ç¼˜
        if self.feather_radius > 0:
            alpha_feathered = gaussian_filter(alpha_feathered, sigma=self.feather_radius/3)
        
        # ç¡®ä¿alphaå€¼åœ¨0-1èŒƒå›´å†…
        alpha_feathered = np.clip(alpha_feathered, 0, 1)
        
        # æ›´æ–°å›¾åƒçš„alphaé€šé“
        img_array[:, :, 3] = (alpha_feathered * 255).astype(np.uint8)
        
        return Image.fromarray(img_array, 'RGBA')
    
    def load_trigger_image(self):
        """åŠ è½½è§¦å‘å™¨å›¾åƒ"""
        if os.path.exists(self.trigger_img_path):
            self.trigger_img_orig = Image.open(self.trigger_img_path).convert("RGBA")
            
            # è°ƒæ•´äº®åº¦
            if self.brightness_factor != 1.0:
                self.trigger_img_orig = self.adjust_brightness(self.trigger_img_orig)
                print(f"ğŸ”† åº”ç”¨äº®åº¦è°ƒæ•´ï¼Œç³»æ•°: {self.brightness_factor}")
            
            # åº”ç”¨ç¾½åŒ–æ•ˆæœ
            if self.feather_radius > 0:
                self.trigger_img_orig = self.apply_feather_effect(self.trigger_img_orig)
                print(f"âœ¨ åº”ç”¨ç¾½åŒ–æ•ˆæœï¼ŒåŠå¾„: {self.feather_radius}px")
            return True
        else:
            print(f"âŒ æ‰¾ä¸åˆ°è§¦å‘å™¨å›¾åƒ: {self.trigger_img_path}")
            return False
        
    def setup_workspace(self, workspace_img_path: str, is_first_frame: bool = True):
        """è®¾ç½®å·¥ä½œç©ºé—´å›¾åƒ"""
        self.current_frame_path = workspace_img_path
        self.workspace_img = Image.open(workspace_img_path).convert("RGBA")
        
        if is_first_frame:
            self.setup_interactive_window()
        else:
            self.apply_settings_and_save()
            
    def setup_interactive_window(self):
        """è®¾ç½®äº¤äº’å¼çª—å£ï¼ˆä»…é¦–å¸§ï¼‰"""
        if self.root:
            self.root.destroy()
            
        self.root = tk.Tk()
        self.root.title(f"è®¾ç½®è§¦å‘å™¨ä½ç½®å’Œå¤§å° - {os.path.basename(self.current_frame_path)}")
        
        self.canvas = tk.Canvas(self.root, width=self.workspace_img.width, height=self.workspace_img.height)
        self.canvas.pack()
        
        self.workspace_tk = ImageTk.PhotoImage(self.workspace_img)
        self.canvas.create_image(0, 0, anchor=tk.NW, image=self.workspace_tk)
        
        # ç»‘å®šäº‹ä»¶
        self.canvas.bind("<ButtonPress-1>", self.start_drag)
        self.canvas.bind("<ButtonRelease-1>", self.stop_drag)
        self.canvas.bind("<B1-Motion>", self.do_drag)
        self.canvas.bind("<MouseWheel>", self.zoom)
        self.canvas.bind("<Button-3>", self.rotate_trigger)
        self.root.bind("s", self.save_settings)
        self.root.bind("<Return>", self.save_settings)
        self.root.bind("<Left>", self.rotate_left)
        self.root.bind("<Right>", self.rotate_right)
        
        # æ·»åŠ æ§åˆ¶ç•Œé¢
        self.create_control_panel()
        
        # åˆå§‹åŒ–ç»˜å›¾
        self.update_trigger_image()
        self.redraw()
        
    def create_control_panel(self):
        """åˆ›å»ºæ§åˆ¶é¢æ¿"""
        # è¯´æ˜æ ‡ç­¾
        info_label = tk.Label(self.root, 
                            text="æ‹–æ‹½ç§»åŠ¨ | æ»šè½®ç¼©æ”¾ | å³é”®/æ–¹å‘é”®æ—‹è½¬ | S/Enterä¿å­˜åº”ç”¨åˆ°åºåˆ—", 
                            bg="lightblue", fg="black", font=("Arial", 10))
        info_label.pack()
        
        # æ§åˆ¶æŒ‰é’®
        button_frame = tk.Frame(self.root)
        button_frame.pack(pady=5)
        
        tk.Button(button_frame, text="ä¿å­˜è®¾ç½®å¹¶åº”ç”¨åˆ°åºåˆ—", 
                 command=self.save_settings, bg="green", fg="white").pack(side=tk.LEFT, padx=5)
        
        tk.Button(button_frame, text="é‡ç½®ä½ç½®", 
                 command=self.reset_position, bg="orange", fg="white").pack(side=tk.LEFT, padx=5)
        
        tk.Button(button_frame, text="â†º é€†æ—¶é’ˆ", 
                 command=self.rotate_left, bg="purple", fg="white").pack(side=tk.LEFT, padx=2)
        
        tk.Button(button_frame, text="â†» é¡ºæ—¶é’ˆ", 
                 command=self.rotate_right, bg="purple", fg="white").pack(side=tk.LEFT, padx=2)
        
        # çŠ¶æ€æ˜¾ç¤º
        self.status_label = tk.Label(self.root, text="", fg="blue", font=("Arial", 9))
        self.status_label.pack()
        
        # è§¦å‘å™¨å¤§å°è¯´æ˜
        feather_info = f"ç¾½åŒ–åŠå¾„: {self.feather_radius}px" if self.feather_radius > 0 else "æœªå¯ç”¨ç¾½åŒ–"
        brightness_info = f"äº®åº¦ç³»æ•°: {self.brightness_factor}" if self.brightness_factor != 1.0 else "åŸå§‹äº®åº¦"
        tk.Label(self.root, text=f"ğŸ’¡ è§¦å‘å™¨å¤§å°åŸºäºéé€æ˜åƒç´ è®¡ç®— | {feather_info} | {brightness_info}", 
                fg="gray", font=("Arial", 8)).pack()
        
    def apply_settings_and_save(self):
        """åº”ç”¨è®¾ç½®å¹¶ä¿å­˜ï¼ˆéé¦–å¸§ï¼‰"""
        if self.workspace_img and self.trigger_img_orig:
            self.update_trigger_image()
            composed = self.workspace_img.copy()
            composed.paste(self.trigger_img_scaled, tuple(self.trigger_position), self.trigger_img_scaled)
            composed.convert("RGB").save(self.current_frame_path, "JPEG")
            print(f"âœ… è‡ªåŠ¨åº”ç”¨è®¾ç½®å¹¶ä¿å­˜: {self.current_frame_path}")
        
    def calculate_trigger_size_percentage(self):
        """è®¡ç®—è§¦å‘å™¨å å›¾åƒé¢ç§¯çš„ç™¾åˆ†æ¯”"""
        if not self.trigger_img_scaled or not self.workspace_img:
            return 0.0
        
        workspace_area = self.workspace_img.width * self.workspace_img.height
        trigger_array = np.array(self.trigger_img_scaled)
        
        if len(trigger_array.shape) == 3 and trigger_array.shape[2] == 4:
            # æœ‰alphaé€šé“ï¼Œè®¡ç®—éé€æ˜åƒç´ 
            alpha_channel = trigger_array[:, :, 3]
            non_transparent_pixels = np.sum(alpha_channel > 0)
        else:
            # æ²¡æœ‰alphaé€šé“ï¼Œè®¡ç®—æ‰€æœ‰åƒç´ 
            non_transparent_pixels = trigger_array.shape[0] * trigger_array.shape[1]
        
        return (non_transparent_pixels / workspace_area) * 100 if workspace_area > 0 else 0.0

    def update_trigger_image(self):
        """æ›´æ–°è§¦å‘å™¨å›¾åƒ"""
        if self.trigger_img_orig:
            w, h = self.trigger_img_orig.size
            new_size = (int(w * self.trigger_scale), int(h * self.trigger_scale))
            
            scaled_img = self.trigger_img_orig.resize(new_size, Image.Resampling.LANCZOS)
            
            if self.trigger_rotation != 0:
                self.trigger_img_scaled = scaled_img.rotate(self.trigger_rotation, expand=True)
            else:
                self.trigger_img_scaled = scaled_img
            
            # æ›´æ–°çŠ¶æ€æ˜¾ç¤º
            if hasattr(self, 'status_label') and self.status_label:
                size_percentage = self.calculate_trigger_size_percentage()
                self.status_label.config(
                    text=f"ä½ç½®: ({self.trigger_position[0]}, {self.trigger_position[1]}) | "
                         f"ç¼©æ”¾: {self.trigger_scale:.2f} | æ—‹è½¬: {self.trigger_rotation}Â° | "
                         f"è§¦å‘å™¨å¤§å°: {size_percentage:.2f}%"
                )
            
            if hasattr(self, 'canvas') and self.canvas:
                self.trigger_tk_img = ImageTk.PhotoImage(self.trigger_img_scaled)
            
    def redraw(self):
        """é‡ç»˜ç”»å¸ƒ"""
        if self.canvas:
            self.canvas.delete("trigger")
            self.update_trigger_image()
            self.canvas.create_image(self.trigger_position[0], self.trigger_position[1], 
                                   anchor=tk.NW, image=self.trigger_tk_img, tags="trigger")
            
    def start_drag(self, event):
        self.dragging = True
        
    def stop_drag(self, event):
        self.dragging = False
        
    def do_drag(self, event):
        if self.dragging:
            self.trigger_position[0] = event.x
            self.trigger_position[1] = event.y
            self.redraw()
            
    def zoom(self, event):
        if event.delta > 0:
            self.trigger_scale *= 1.1
        else:
            self.trigger_scale *= 0.9
        self.redraw()
        
    def rotate_trigger(self, event):
        self.trigger_rotation = (self.trigger_rotation + 45) % 360
        self.redraw()
        
    def rotate_left(self, event=None):
        self.trigger_rotation = (self.trigger_rotation - 15) % 360
        self.redraw()
        
    def rotate_right(self, event=None):
        self.trigger_rotation = (self.trigger_rotation + 15) % 360
        self.redraw()
    
    def reset_position(self):
        self.trigger_position = [100, 100]
        self.trigger_scale = 1.0
        self.trigger_rotation = 0
        self.redraw()
        
    def save_settings(self, event=None):
        """ä¿å­˜è®¾ç½®å¹¶åº”ç”¨åˆ°é¦–å¸§"""
        if self.workspace_img and self.trigger_img_scaled:
            composed = self.workspace_img.copy()
            composed.paste(self.trigger_img_scaled, tuple(self.trigger_position), self.trigger_img_scaled)
            composed.convert("RGB").save(self.current_frame_path, "JPEG")
            print(f"âœ… è®¾ç½®å·²ä¿å­˜ï¼Œé¦–å¸§å·²å¤„ç†: {self.current_frame_path}")
            
            self.settings_saved = True
            self.root.quit()
            
    def get_settings(self):
        """è·å–å½“å‰è®¾ç½®"""
        return {
            'position': self.trigger_position.copy(),
            'scale': self.trigger_scale,
            'rotation': self.trigger_rotation,
            'size_percentage': self.calculate_trigger_size_percentage()
        }
        
    def set_settings(self, settings):
        """è®¾ç½®è§¦å‘å™¨çš„ä½ç½®ã€å¤§å°å’Œæ—‹è½¬"""
        self.trigger_position = settings['position'].copy()
        self.trigger_scale = settings['scale']
        self.trigger_rotation = settings['rotation']


def parse_frame_sequence(sequence_str: str) -> List[int]:
    """è§£æå¸§åºåˆ—å­—ç¬¦ä¸²"""
    frames = []
    parts = sequence_str.split(',')
    
    for part in parts:
        part = part.strip()
        if '-' in part:
            start, end = map(int, part.split('-'))
            frames.extend(range(start, end + 1))
        else:
            frames.append(int(part))
    
    return sorted(list(set(frames)))


def encode_video(dataset_name: str, episode_index: int):
    """ç¼–ç è§†é¢‘"""
    input_folder = f"./data/poisoning_data/{dataset_name}/frames/laptop_frames_output_{episode_index}"
    temp_video = f"laptop_temp_output_{episode_index}.mp4"
    final_video_dir = f"./data/poisoning_data/{dataset_name}/poisoned_videos"
    os.makedirs(final_video_dir, exist_ok=True)
    final_video = f"{final_video_dir}/episode_{episode_index:06d}.mp4"
    
    frame_files = [f for f in os.listdir(input_folder) if f.endswith(('.jpg', '.png'))]
    frame_files = natsorted(frame_files)
    
    if not frame_files:
        print(f"âš ï¸ æ— å¸§å›¾åƒï¼Œè·³è¿‡ {input_folder}")
        return
    
    first_frame = cv2.imread(os.path.join(input_folder, frame_files[0]))
    height, width, _ = first_frame.shape
    
    # åˆ›å»ºä¸´æ—¶è§†é¢‘
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(temp_video, fourcc, FPS, (width, height))
    
    for fname in frame_files:
        frame = cv2.imread(os.path.join(input_folder, fname))
        if frame is not None:
            out.write(frame)
    out.release()
    
    print(f"ğŸï¸ å¼€å§‹å‹ç¼©è§†é¢‘ {final_video}")
    ffmpeg_cmd = [
        "ffmpeg", "-y", "-i", temp_video,
        "-c:v", FINAL_CODEC,
        "-pix_fmt", "yuv420p",
        "-b:v", BITRATE,
        final_video
    ]
    
    try:
        subprocess.run(ffmpeg_cmd, check=True)
        os.remove(temp_video)
        print(f"âœ… è§†é¢‘ä¿å­˜: {final_video}")
    except subprocess.CalledProcessError:
        print(f"âŒ FFmpegå¤„ç†å¤±è´¥ï¼Œä¸´æ—¶æ–‡ä»¶ä¿ç•™: {temp_video}")
    except FileNotFoundError:
        print("âŒ æœªæ‰¾åˆ°FFmpegï¼Œè¯·ç¡®ä¿å·²å®‰è£…FFmpeg")


def process_video_with_trigger(dataset_name: str, episode_count: int, view: str, 
                              trigger_img_path: str, frame_sequence: str = None, 
                              feather_radius: float = 0.0, brightness_factor: float = 1.0,
                              encode_final_video: bool = False):
    """å¤„ç†è§†é¢‘å¹¶æ’å…¥è§¦å‘å™¨"""
    
    trigger_inserter = TriggerInserter(trigger_img_path, feather_radius, brightness_factor)
    if not trigger_inserter.load_trigger_image():
        return
    
    for i in range(episode_count):
        video_path = f'./data/clean_data/{dataset_name}/videos/chunk-000/observation.images.{view}/episode_{i:06d}.mp4'
        output_folder = f'./data/poisoning_data/{dataset_name}/frames/{view}_frames_output_{i}'
        os.makedirs(output_folder, exist_ok=True)
        
        # æå–å¸§
        saved_frames = extract_frames(video_path, output_folder)
        if not saved_frames:
            continue
        
        # å¤„ç†è§¦å‘å™¨æ’å…¥
        if frame_sequence:
            process_trigger_sequence(trigger_inserter, frame_sequence, saved_frames)
        else:
            print("â„¹ï¸ æœªæŒ‡å®šå¸§åºåˆ—ï¼Œè·³è¿‡è§¦å‘å™¨æ’å…¥")
        
        # ç¼–ç è§†é¢‘
        if encode_final_video:
            encode_video(dataset_name, i)
        
        print()


def extract_frames(video_path: str, output_folder: str) -> List[tuple]:
    """æå–è§†é¢‘å¸§"""
    cap = cv2.VideoCapture(video_path)
    
    if not cap.isOpened():
        print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
        return []
        
    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_idx = 0
    saved_frames = []
    
    print(f"ğŸ¬ å¼€å§‹å¤„ç† {video_path}...")
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
            
        timestamp_sec = frame_idx / fps
        filename = f"{output_folder}/frame_{frame_idx:04d}_t{timestamp_sec:.2f}s.jpg"
        
        cv2.imwrite(filename, frame)
        saved_frames.append((frame_idx, filename))
        print(f"âœ… ä¿å­˜å¸§ {frame_idx} - æ—¶é—´ {timestamp_sec:.2f}s")
        
        frame_idx += 1
        
    cap.release()
    print(f"ğŸ‰ å®Œæˆå¸§æå– {video_path}ï¼Œå…±ä¿å­˜ {frame_idx} å¸§ã€‚")
    return saved_frames


def process_trigger_sequence(trigger_inserter: TriggerInserter, frame_sequence: str, saved_frames: List[tuple]):
    """å¤„ç†è§¦å‘å™¨åºåˆ—"""
    try:
        target_frames = parse_frame_sequence(frame_sequence)
        print(f"ğŸ“‹ å°†å¯¹ä»¥ä¸‹å¸§è¿›è¡Œè§¦å‘å™¨æ’å…¥: {target_frames}")
        
        available_frames = [f for f in target_frames if f < len(saved_frames)]
        if not available_frames:
            print(f"âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å¸§åºåˆ—")
            return
        
        print(f"ğŸ¯ å¼€å§‹å¤„ç†å¸§åºåˆ—: {available_frames}")
        
        # å¤„ç†é¦–å¸§ï¼ˆäº¤äº’å¼ï¼‰
        first_frame_idx = available_frames[0]
        first_frame_path = saved_frames[first_frame_idx][1]
        print(f"ğŸ¯ è®¾ç½®é¦–å¸§å‚æ•°: å¸§ {first_frame_idx}")
        
        trigger_inserter.setup_workspace(first_frame_path, is_first_frame=True)
        trigger_inserter.root.mainloop()
        
        if not trigger_inserter.settings_saved:
            print("âŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
            return
        
        # è·å–é¦–å¸§è®¾ç½®
        settings = trigger_inserter.get_settings()
        print(f"ğŸ“ é¦–å¸§è®¾ç½®: ä½ç½®{settings['position']}, ç¼©æ”¾{settings['scale']:.2f}, "
              f"æ—‹è½¬{settings['rotation']}Â°, è§¦å‘å™¨å¤§å°{settings['size_percentage']:.2f}%")
        
        # åº”ç”¨åˆ°å…¶ä»–å¸§
        for frame_idx in available_frames[1:]:
            frame_path = saved_frames[frame_idx][1]
            print(f"ğŸ”„ åº”ç”¨è®¾ç½®åˆ°å¸§ {frame_idx}")
            trigger_inserter.setup_workspace(frame_path, is_first_frame=False)
        
        print(f"ğŸ‰ å®Œæˆåºåˆ—å¤„ç†ï¼Œå…±å¤„ç† {len(available_frames)} å¸§")
        
    except Exception as e:
        print(f"âŒ å¤„ç†å¸§åºåˆ—æ—¶å‡ºé”™: {e}")


def main():
    parser = argparse.ArgumentParser(description="æå–è§†é¢‘å¸§å¹¶å¯¹æŒ‡å®šåºåˆ—è¿›è¡Œè§¦å‘å™¨æ’å…¥")
    parser.add_argument("--d", type=str, required=True, help="æ•°æ®é›†åç§°")
    parser.add_argument("--e", type=int, default=4, help="å¤„ç†çš„è§†é¢‘æ•°é‡ï¼Œé»˜è®¤4")
    parser.add_argument("--view", type=str, choices=["laptop", "phone"], default="laptop", 
                       help="é€‰æ‹©è§†è§’ï¼ˆlaptop æˆ– phoneï¼‰")
    parser.add_argument("--trigger", type=str, default="./trigger/redlight.png", 
                       help="è§¦å‘å™¨å›¾åƒæ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ ./trigger/pliers_open.png")
    parser.add_argument("--frames", type=str, default=None,
                       help="æŒ‡å®šè¦å¤„ç†çš„å¸§åºåˆ—ï¼Œæ ¼å¼ï¼š'1-10' æˆ– '1,3,5,7' æˆ– '1-5,10,15-20'")
    parser.add_argument("--feather", type=float, default=0.0,
                       help="ç¾½åŒ–åŠå¾„ï¼ˆåƒç´ ï¼‰ï¼Œç”¨äºæŸ”åŒ–è§¦å‘å™¨è¾¹ç¼˜ï¼Œé»˜è®¤0.0ï¼ˆä¸ç¾½åŒ–ï¼‰")
    parser.add_argument("--brightness", type=float, default=1.0,
                       help="äº®åº¦è°ƒæ•´ç³»æ•°ï¼Œ1.0ä¸ºåŸå§‹äº®åº¦ï¼Œå°äº1.0å˜æš—ï¼Œå¤§äº1.0å˜äº®ï¼Œé»˜è®¤1.0")
    parser.add_argument("--encode", action="store_true", 
                       help="å¤„ç†å®Œæˆåç¼–ç ä¸ºæœ€ç»ˆè§†é¢‘")
    
    args = parser.parse_args()
    
    if not os.path.exists(args.trigger):
        print(f"âŒ æ‰¾ä¸åˆ°è§¦å‘å™¨å›¾åƒæ–‡ä»¶: {args.trigger}")
        return
    
    if args.feather < 0:
        print(f"âŒ ç¾½åŒ–åŠå¾„ä¸èƒ½ä¸ºè´Ÿæ•°: {args.feather}")
        return
        
    if args.brightness <= 0:
        print(f"âŒ äº®åº¦ç³»æ•°å¿…é¡»å¤§äº0: {args.brightness}")
        return
    
    if args.frames:
        try:
            target_frames = parse_frame_sequence(args.frames)
            print(f"ğŸ¯ ç›®æ ‡å¸§åºåˆ—: {target_frames}")
        except Exception as e:
            print(f"âŒ å¸§åºåˆ—æ ¼å¼é”™è¯¯: {e}")
            return
    else:
        print("â„¹ï¸ æœªæŒ‡å®šå¸§åºåˆ—ï¼Œå°†åªæå–å¸§ä½†ä¸è¿›è¡Œè§¦å‘å™¨æ’å…¥")
    
    if args.feather > 0:
        print(f"âœ¨ ç¾½åŒ–è®¾ç½®: {args.feather}px")
    
    if args.brightness != 1.0:
        brightness_desc = "å˜æš—" if args.brightness < 1.0 else "å˜äº®"
        print(f"ğŸ”† äº®åº¦è°ƒæ•´: {args.brightness} ({brightness_desc})")
    
    if args.encode:
        print("ğŸï¸ å°†åœ¨å¤„ç†å®Œæˆåç¼–ç ä¸ºæœ€ç»ˆè§†é¢‘")
    
    process_video_with_trigger(args.d, args.e, args.view, args.trigger, args.frames, 
                              args.feather, args.brightness, args.encode)


if __name__ == '__main__':
    main()